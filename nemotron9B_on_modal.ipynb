{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984ae22e",
   "metadata": {},
   "source": [
    "Register on [modal.com](https://modal.com/signup) and avail of $30 free credit per month.\n",
    "\n",
    "Then run:\n",
    "```bash\n",
    "pip install modal\n",
    "modal setup  # to authenticate (if this doesn’t work, try python -m modal setup)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c7c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemotron_inference_modal_9B import serve, app\n",
    "import urllib\n",
    "\n",
    "app.app_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c86fb",
   "metadata": {},
   "source": [
    "Let's see if we can find our app for serving the Nemotron Nano 9B model. If not, let's deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cdaca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ap-z3NEtW68yuO8zUB5Fz1po8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not app.app_id:\n",
    "    try:\n",
    "        app.lookup(\"nemotron-nano-9B-v2-inference\")\n",
    "    except:\n",
    "        app.deploy()\n",
    "\n",
    "app.app_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d805b",
   "metadata": {},
   "source": [
    "Because our `serve` `Function` (defined in `nemotron_inference_modal_9B.py`) has the `@modal.web_server(port=VLLM_PORT, startup_timeout=10 * MINUTES)` decorator, it comes equipped with a web server we can spin up by hitting its `url`.\n",
    "\n",
    "Let's first get the `url` for the `serve` `Function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6caf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://rosmulski--nemotron-nano-9b-v2-inference-serve.modal.run'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modal\n",
    "f = modal.Function.from_name(\"nemotron-nano-9B-v2-inference\", \"serve\")\n",
    "url = f.get_web_url()\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e60f0",
   "metadata": {},
   "source": [
    "We can hit the `/health` endpoint to bring the app up.\n",
    "\n",
    "The first time around, tt can take ~3 minutes.\n",
    "\n",
    "Once that's done, our app will stay up as long as it receives a request within `scaledown_window` seconds (5 minutes in our case, given tha params passed to the `@app.function` decorator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f93a1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are up and running!\n"
     ]
    }
   ],
   "source": [
    "with urllib.request.urlopen(f\"{url}/health\") as response:\n",
    "    data = response.read().decode('utf-8')\n",
    "    if response.status == 200:\n",
    "        print(\"We are up and running!\")\n",
    "    else:\n",
    "        print(f\"Health check failed. Review logs at modal.com/apps.\\nResponse: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe0ea4f",
   "metadata": {},
   "source": [
    "And we are ready to talk to our LLM! :)\n",
    "\n",
    "Let's check the available models (should be just our `NVIDIA-Nemotron-Nano-9B-v2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01af0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='nvidia/NVIDIA-Nemotron-Nano-9B-v2', created=1757930137, object='model', owned_by='vllm', root='nvidia/NVIDIA-Nemotron-Nano-9B-v2', parent=None, max_model_len=131072, permission=[{'id': 'modelperm-2b0c65b86e37479e9405cb4020cb0a02', 'object': 'model_permission', 'created': 1757930137, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}])], object='list')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=url + '/v1')\n",
    "client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c721ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user is asking if semicolons are optional in JavaScript. Let me start by recalling what I know about JavaScript syntax.\n",
      "\n",
      "Semicolons are used to terminate statements, but I remember that JavaScript has automatic semicolon insertion (ASI). So the engine might add a semicolon where it's needed. But wait, does that mean they're optional?\n",
      "\n",
      "Hmm, but there are some cases where you have to use them. Like when you're writing multiple statements on the same line. For example, if you have 'var a = 1; var b = 2;' versus 'var a = 1 var b = 2;'—the latter would be parsed as 'var a = 1' and 'var b = 2' because of ASI. But if you write them without semicolons on the same line, it might cause issues. So in that case, are semicolons required?\n",
      "\n",
      "Also, in some code structures, like when using commas or other characters that could be ambiguous, semicolons might be necessary to prevent ASI from adding them in the wrong place. For instance, if you have 'function foo() { return 1 + 2' without a semicolon, ASI might add it after the 2, which is correct. But maybe in other scenarios, like after a closing brace, you don't need them.\n",
      "\n",
      "Another point is that even though ASI works, relying on it can lead to bugs. If you have a line like 'var a = 1 1;', ASI would insert a semicolon between the two 1s, turning it into two variables. That's a problem. So the user needs to be cautious.\n",
      "\n",
      "Also, when returning multiple values or using certain operators, the presence of semicolons can affect parsing. So while they are technically optional in many cases due to ASI, it's not always safe to omit them. Best practice is to use them consistently to avoid confusion.\n",
      "\n",
      "So the answer is that semicolons are optional in JavaScript because of ASI, but it's generally recommended to include them to prevent potential errors and make the code more readable. There are edge cases where omitting them can cause issues, so being aware of those is important.\n",
      "</think>\n",
      "\n",
      "In JavaScript, **semicolons are optional** due to **Automatic Semicolon Insertion (ASI)**. The JavaScript engine will automatically insert semicolons in many cases to separate statements. However, this behavior can lead to unexpected results in certain scenarios, so it's generally considered a best practice to **explicitly use semicolons**.\n",
      "\n",
      "### When Semicolons Are Optional (ASI Applies):\n",
      "1. **End of Line**: If a statement ends with a newline (`\\n`), a semicolon is typically not required (though it's still optional).\n",
      "2. **Specified Positions**: ASI inserts semicolons at specific locations (e.g., between tokens like `return` and `;`).\n",
      "\n",
      "### When Semicolons Are **Required** (ASI Fails or Causes Issues):\n",
      "1. **Same Line, Multiple Statements**:\n",
      "   - Without a semicolon, ASI might misinterpret the code.  \n",
      "     Example:\n",
      "     ```javascript\n",
      "     // Works (ASI adds semicolon between variables)\n",
      "     var a = 1, b = 2;\n",
      "     ```\n",
      "     But if written without commas or properly spaced:\n",
      "     ```javascript\n",
      "     // Fail (ASI inserts semicolon between `1` and `b`, creating two statements)\n",
      "     var a = 1 1; // Parsed as `var a = 1; 1;`\n",
      "     ```\n",
      "\n",
      "2. **After `return`**:\n",
      "   - Omitting a semicolon after `return` can cause errors if the return value is not properly terminated.\n",
      "     ```javascript\n",
      "     return 1 // Valid (ASI might work, but not guaranteed in all cases)\n",
      "     ```\n",
      "\n",
      "3. **Avoiding Ambiguity**:\n",
      "   - Semicolons prevent ASI from inserting them in unintended places.\n",
      "\n",
      "### Best Practices:\n",
      "- Use semicolons consistently to avoid reliance on ASI.\n",
      "- Always use semicolons when writing multiple statements on the same line.\n",
      "- Consider using tools or linters (like ESLint) to enforce semicolon usage.\n",
      "\n",
      "In summary: **Semicolons are optional in theory but highly recommended in practice** for clarity and reliability.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"nvidia/NVIDIA-Nemotron-Nano-9B-v2\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"Talk like a pirate.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a7a5d6",
   "metadata": {},
   "source": [
    "Two things become apparent:\n",
    "1. Nemotron 9B cannot talk like a pirate!\n",
    "    - This in fact might be a good thing. There has been a lot of talk recently how \"reasoning models\" lack personality and have been hyper-tuned to squeeze out as much intelligence on certain tasks (math, programming, etc) from the weights as possible. This is exactly what I am hoping to get from this model. In that light, this behavior is a good sign.\n",
    "2. You can't use API calls like this in your code.\n",
    "\n",
    "Let me elaborate on the 2nd point.\n",
    "\n",
    "How do we ensure we use more of something? We reduce the friction around using said thing.\n",
    "\n",
    "We could wrap the `client.responses.create` calls into functions (and build the parsing tooling around it). But that strikes me as a lot of work and still I wouldn't be able to come up on my own with something even remotely as awesome as the library I am going to introduce you to next!\n",
    "\n",
    "I nearly universally hate AI frameworks and SDKs, but I have fallen in love with `BAML`.\n",
    "\n",
    "The problem I was trying to solve was: \"how do I call any model in a simple yet powerful way?\" What if I would like to get structured output and tool calling?\n",
    "\n",
    "Some of the libraries that I tried came close, but none provided the entire functionality. `BAML` doesn't only meet the above criteria, but it also brings [something else that is very unique and valuable](https://boundaryml.com/blog/sota-function-calling?q=0) in its own right.\n",
    "\n",
    "Let me show you what you can do with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff627d",
   "metadata": {},
   "source": [
    "# Basic Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8092a5a",
   "metadata": {},
   "source": [
    "To be able to execute the cells below, please follow the installation steps outlined [here](https://docs.boundaryml.com/guide/installation-language/python)\n",
    "\n",
    "The following cell performs some config that is generally not necessary (you can specify all this information via `baml_src/clients.baml`).\n",
    "\n",
    "But by adding this cell, I am saving you the need to open the `clients.baml` file and edit it just for the purposes of this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f47efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BAML] Log level set to \u001b[91mERROR\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from baml_py import ClientRegistry\n",
    "from baml_py.baml_py import set_log_level\n",
    "set_log_level(\"ERROR\")\n",
    "\n",
    "cr = ClientRegistry()\n",
    "cr.add_llm_client(name='NemotronOnModal', provider='openai-generic', options={\n",
    "        \"model\": \"nvidia/NVIDIA-Nemotron-Nano-9B-v2\",\n",
    "        \"base_url\": url + '/v1',\n",
    "        \"api_key\": \"\"\n",
    "    })\n",
    "\n",
    "cr.set_primary('NemotronOnModal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec10eb",
   "metadata": {},
   "source": [
    "## Standard Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2cb1f",
   "metadata": {},
   "source": [
    "The output of the model is quite verbose  we are not — we are not applying any parsing to it. This is just for demonstration, we would never use the model like this in actual code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d74a712f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, the user is asking if semicolons are optional in JavaScript. Let me start by recalling what I know about semicolons in JS.\n",
       "\n",
       "First, I remember that JavaScript is a loosely typed language, and its syntax allows for certain flexibility. Semicolons are used to terminate statements, right? Like in many languages, you put them at the end of a line to indicate the end of a command.\n",
       "\n",
       "But wait, JavaScript has something called Automatic Semicolon Insertion (ASI). From what I've studied, this feature allows the interpreter to add a semicolon where it's missing if it can infer the end of a statement. So in cases where you forget to put a semicolon, the engine might automatically add one. However, this isn't always reliable. There are situations where ASI can fail, leading to unexpected behavior.\n",
       "\n",
       "For example, if a line ends with a certain character that could be ambiguous, ASI might not add the semicolon correctly. Like if a line ends with a comma or a closing parenthesis, the parser might not know where the statement ends. That could cause errors later on.\n",
       "\n",
       "So even though semicolons are technically optional because of ASI, relying on them is discouraged. It's considered a bad practice because it introduces ambiguity. Developers are advised to use semicolons explicitly to avoid potential bugs, especially when writing code that might be minified or processed by tools that could alter the code in ways that remove or add semicolons.\n",
       "\n",
       "Another point to consider is consistency. If a developer sometimes uses semicolons and sometimes doesn't, it can make the code harder to read or maintain. Also, different environments or code minifiers might behave differently with ASI, leading to inconsistent results.\n",
       "\n",
       "Are there specific cases where semicolons are required even with ASI? Yes. For instance, if you have two statements on the same line without a semicolon, it might concatenate them into one statement if ASI can't figure out where to split them. Like var a = 1; var b = 2; versus var a = 1 var b = 2; the latter might become var a = 1var b = 2; which is a syntax error.\n",
       "\n",
       "Also, when using certain operators or expressions that end with a symbol that looks like a statement, ASI might not work as intended. For example, ending a line with a function parameter list or an object literal.\n",
       "\n",
       "So putting it all together, the answer is that yes, semicolons are optional in JavaScript due to ASI, but it's not recommended to rely on that. Best practice is to use them explicitly to prevent potential issues.\n",
       "\n",
       "Wait, but I should check if there are any edge cases or recent changes. ES6 or later versions didn't change the ASI rules, I think. So the core idea holds. Also, maybe mention that in some cases, even with ASI, you need to add semicolons, like after a return statement or in certain function definitions.\n",
       "\n",
       "Another example: if you have a line that's a single expression and then another line that starts with a variable declaration, without a semicolon, it could be parsed incorrectly. Like function foo() { var x = 5; var y = 10; } versus function foo() { var x =5 var y=10; }, which would merge the var statements into one, but ASI might not catch that. Wait, in that case, ASI would add a semicolon after the 5 and then see the var y... as a new statement. Wait, maybe not. If you have \"var x=5 var y=10\", ASI would add a semicolon after the 5, making it \"var x=5; var y=10\", which is correct. Hmm. Maybe that example isn't the best. Another example could be when a line ends with a comma, which might not trigger ASI properly.\n",
       "\n",
       "Alternatively, if you have something like:\n",
       "\n",
       "var obj = { a: 1\n",
       "b: 2 };\n",
       "\n",
       "Here, without a semicolon after the first line, ASI might not add it correctly, leading to a syntax error.\n",
       "\n",
       "In conclusion, while semicolons are optional in JavaScript due to ASI, relying on them can lead to bugs, so it's better to include them explicitly.\n",
       "</think>\n",
       "\n",
       "Yes, semicolons are **technically optional** in JavaScript due to **Automatic Semicolon Insertion (ASI)**, a feature of the JavaScript engine that adds missing semicolons in some cases. However, relying on ASI is **not recommended** due to potential ambiguity and bugs. Here's a breakdown:\n",
       "\n",
       "### Key Points:\n",
       "1. **Automatic Semicolon Insertion (ASI):**\n",
       "   - The JavaScript engine automatically adds semicolons where possible to terminate statements.\n",
       "   - Example: `var x = 5;` can be written as `var x = 5`.\n",
       "\n",
       "2. **When ASI Works:**\n",
       "   - At the end of a line (common case).\n",
       "   - When the line ends with a `}`, `)`, or `]` (e.g., closing brackets).\n",
       "\n",
       "3. **When ASI Fails:**\n",
       "   - When the line ends with a character or structure that could be misinterpreted (e.g., commas, certain operators).\n",
       "   - Example: Forgetting a semicolon between statements on the same line:\n",
       "     ```javascript\n",
       "     var a = 1 var b = 2; // ❌ Becomes `var a = 1var b = 2;` (invalid)\n",
       "     ```\n",
       "   - When lines end with commas or other ambiguous characters.\n",
       "\n",
       "4. **Best Practices:**\n",
       "   - **Always use semicolons explicitly** to avoid reliance on ASI.\n",
       "   - Enforce consistent coding style (e.g., ESLint rules can enforce semicolons).\n",
       "   - Semicolons prevent parsing errors, especially in complex or minified code.\n",
       "\n",
       "### Why Avoid Relying on ASI?\n",
       "- **Ambiguity:** The engine might misinterpret where a statement ends.\n",
       "- **Minifiers:** Tools may remove semicolons during compression, breaking code.\n",
       "- **Readability:** Explicit semicolons improve code clarity for others (and future you).\n",
       "\n",
       "### Conclusion:\n",
       "While semicolons are optional in theory, they are essential in practice for robust, maintainable, and error-free JavaScript code.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from baml_client import b\n",
    "from IPython.display import Markdown\n",
    "\n",
    "r = b.GetCompletion(\"Are semicolons optional in JavaScript?\", { \"client_registry\": cr })\n",
    "Markdown(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6d903",
   "metadata": {},
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a6673",
   "metadata": {},
   "source": [
    "Very often you want to get something specific from a model:\n",
    "* a yes or no answer\n",
    "* a score\n",
    "* a piece of code that achieves something\n",
    "\n",
    "`BAML` makes this super convenient plus it adds a bit of secret sauce so that the experience and performance you get [is better](https://boundaryml.com/blog/structured-output-from-llms) to what you might expect when using standard SDKs.\n",
    "\n",
    "Let's look at an example.\n",
    "\n",
    "Below we have text taken from [HF's model card](https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-9B-v2) for the Nemotron model we are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e2309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\\\n",
    "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained from scratch by NVIDIA, and designed as a unified model for both reasoning and non-reasoning tasks. It responds to user queries and tasks by first generating a reasoning trace and then concluding with a final response. The model's reasoning capabilities can be controlled via a system prompt. If the user prefers the model to provide its final answer without intermediate reasoning traces, it can be configured to do so, albeit with a slight decrease in accuracy for harder prompts that require reasoning. Conversely, allowing the model to generate reasoning traces first generally results in higher-quality final solutions to queries and tasks.\n",
    "\n",
    "The model uses a hybrid architecture consisting primarily of Mamba-2 and MLP layers combined with just four Attention layers. For the architecture, please refer to the Nemotron-H tech report. The model was trained using Megatron-LM and NeMo-RL.\n",
    "\n",
    "The supported languages include: English, German, Spanish, French, Italian, and Japanese. Improved using Qwen.\n",
    "\n",
    "This model is ready for commercial use.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cb10f",
   "metadata": {},
   "source": [
    "Let's see if we can extract:\n",
    "- the libraries the model was trained \n",
    "- the supported langauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed58667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LibrariesAndLanguages(used_libraries=['Megatron-LM', 'NeMo-RL'], supported_languages=['English', 'German', 'Spanish', 'French', 'Italian', 'Japanese'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.ExtractLibrariesAndLanguages(text, { \"client_registry\": cr })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432fded6",
   "metadata": {},
   "source": [
    "At this point, you might be wondering where do the functions like the `ExtractLibrariesAndLanguages` above come from? You define them using `BAML` — a domain specific langauge — in `baml_src`.\n",
    "\n",
    "But doesn't having to mess with files on disk make my life harder? Why can't I define everything inline?\n",
    "\n",
    "`BAML` comes with a lot of streamlined tools, like the ability to define test cases anditerate on your functionality directly in VS Code, helpful syntax parsers, etc.\n",
    "\n",
    "There is not an ounce of functionality that feels out of place or that was put in with the intention of achieving anything else than programmer productivity and possibly even happiness. I suspect 3 things:\n",
    "* `BoundaryML` are not your run-of-the-mill programmers you are likely to run into at the \"JAVA Programming Patterns Weekly Appreciation Club\" \n",
    "* they are probably developing `BAML` for internal needs (dogfooding does wonders to your software!)\n",
    "* they really know what they are doing (as evidenced on their superb [YT channel](https://www.youtube.com/@boundaryml))\n",
    "\n",
    "Let's finish strong by building a small chat bot and showcasing tool calling (both taken from `BAML` [examples](https://docs.boundaryml.com/examples/interactive-examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3588e",
   "metadata": {},
   "source": [
    "## Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce7caa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: Hi, my name is Radek.\n",
      "AI: Hi Radek! Nice to meet you. How can I help you today? If you tell me what you’re working on or what you’re curious about, I’ll tailor my assistance.\n",
      "\n",
      "You: What is the meaning of life?\n",
      "AI: Hi Radek. Great question, and there isn’t one universal answer. Here are a few common perspectives:\n",
      "\n",
      "- Personal meaning: Many people find meaning by deepening relationships, growing as a person, and helping others.\n",
      "- Existential view: Life may not have inherent meaning, but we get to create our own purpose through our choices and how we live.\n",
      "- Philosophical angles: Some find meaning in pursuing virtues or honing their talents (eudaimonia); others embrace the idea of the absurd and still choose to live fully.\n",
      "- Spiritual/religious view: Meaning is often seen as aligning with a larger purpose, God, or a moral framework.\n",
      "- Scientific view: The universe isn’t designed with a meaning, but we can derive meaning from curiosity, wonder, and the impact we have on others.\n",
      "\n",
      "A practical approach is to identify what you value most (love, curiosity, service, growth) and build daily actions around those values. You can also combine perspectives—seek connection, learn continuously, and contribute to something bigger than yourself.\n",
      "\n",
      "If you share a bit about your beliefs or what you value most, I can help tailor a personal meaning framework for you.\n",
      "\n",
      "You: Buddhism is probably closest to my outlook on life.\n",
      "AI: Great—that makes sense. From a Buddhist perspective, the meaning of life isn’t a single cosmic answer but something you cultivate: freedom from suffering for yourself and others, and awakening to reality as it is.\n",
      "\n",
      "Core ideas:\n",
      "- Four Noble Truths: suffering exists (dukkha), it has a cause (craving/ignorance), it can end, and there’s a path to that end.\n",
      "- The path: the Eightfold Path — wisdom (right view, right intention), ethics (right speech, right action, right livelihood), and mental training (right effort, right mindfulness, right concentration).\n",
      "- Impermanence and non-self: clinging to things, people, or even identity leads to suffering; recognizing impermanence helps loosen that grip.\n",
      "- Interdependence: all beings are connected; awakening includes compassion for others (karuna, metta).\n",
      "\n",
      "Practical takeaway:\n",
      "- Daily practice: a short meditation (mindfulness or insight) for 10–20 minutes, plus brief mindful moments throughout the day.\n",
      "- Ethics in daily life: speak truthfully and kindly, act with integrity, and avoid harming others.\n",
      "- Mindful reflection: notice what you cling to, observe it with curiosity, and let go where appropriate.\n",
      "- Cultivate compassion: wish others well, and look for ways to help reduce suffering around you.\n",
      "\n",
      "If you want, I can tailor this to a specific Buddhist tradition (Theravada, Mahayana, Vajrayana) and create a simple week-long starter plan. Also tell me about your daily routine and any practices you already do, and I’ll adapt.\n",
      "\n",
      "You: Do you still remember my name?\n",
      "AI: Yes—your name is Radek. I remember it from our chat, and I’ll use it here unless you tell me otherwise.\n",
      "\n",
      "You: Hey, are you there?\n",
      "AI: Yes, I’m here, Radek. What would you like to work on today? We can continue with Buddhism guidance, tailor a week-long practice plan, or chat about something else.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from baml_client import b\n",
    "from baml_client.types import MyUserMessage\n",
    "\n",
    "messages: list[MyUserMessage] = []\n",
    "\n",
    "while True:\n",
    "    content = input(\"Enter your message (or 'quit' to exit): \")\n",
    "    if content.lower() == 'quit':\n",
    "        break\n",
    "    print(f\"You: {content}\")\n",
    "    messages.append(MyUserMessage(role=\"user\", content=content))\n",
    "    \n",
    "    agent_response = b.ChatWithLLM(messages=messages);\n",
    "    print(f\"AI: {agent_response}\")\n",
    "    print()\n",
    "    \n",
    "    # Add the agent's response to the chat history\n",
    "    messages.append(MyUserMessage(role=\"assistant\", content=agent_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4289fde7",
   "metadata": {},
   "source": [
    "## Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794c78d",
   "metadata": {},
   "source": [
    "Tool calling in `BAML` is... unusual.\n",
    "\n",
    "### What I like about it\n",
    "\n",
    "You should always think at least twice whether you really need an agent. Most of the time, structured flow is the way to go (where the orchestration of what happens is done in code, not handled via the LLM).\n",
    "\n",
    "`BAML` gives you the tools to fill in the gap between no tool calling at all and fully agentic tool calling. Meaning, you can give your model as much *agency* as you believe is most conductive to achieving your goals.\n",
    "\n",
    "### What I am concerned about\n",
    "\n",
    "As long-horizon agentic workflows are going to be trained more and more into the models, will this way of tool calling continue to be the best? But I have very little experience with this approach — maybe that is not something worth worrying at this point in time.\n",
    "\n",
    "Without further ado, let's give tool calling using the `BAML` way a go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03b1bb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content=\"I'm just a language model, so I don't have feelings or a physical state. But I'm here and ready to help you with any questions you might have!\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.ToolCallOrMessage('How are you doing today?', { \"client_registry\": cr })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "924b714d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetWeatherAPI(location='Brisbane')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = b.ToolCallOrMessage('What is the weather like in Brisbane?', { \"client_registry\": cr })\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8d305ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Call... Call GetWeatherAPI passing in location='Brisbane' and optionally use this information in subsequent calls to the model\n"
     ]
    }
   ],
   "source": [
    "if isinstance(r, str):\n",
    "    print(\"AI:\", r)\n",
    "else:\n",
    "    print(f\"Tool Call... Call {r.__class__.__name__} passing in {r} and optionally use this information in subsequent calls to the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6655332c",
   "metadata": {},
   "source": [
    "On one hand, we get greater flexiblity with this approach. The pattern where:\n",
    "```\n",
    "prompt -> tool call requested by the model -> tool result is passed back to the model -> model returns a response or another tool call\n",
    "```\n",
    "is just one of many that we can implement.\n",
    "\n",
    "On the other hand, having a tool loop where the schema is inferred from a Python function (or multiple functions) passed to the model, would probably be nice.\n",
    "\n",
    "Again, it all goes back to the notion that very likely, for most use cases today, one would still be better off creating a workflow rather than building an agent.\n",
    "\n",
    "This is probably still true, even if we could call Opus and GPT-5 without limitations, if we removed the cost and latency of the calls from the equation. Most likely, the reliability is simply not there yet, especially for more niche scenarios (ones not directly related to coding or deep research).\n",
    "\n",
    "But as we live in a world where you cannot just wave away cost and latency, my bet is on SLMs like `Nemotron 9B v2`, and surprisingly, SLMs and `BAML` are a match made in heaven. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce1ec2",
   "metadata": {},
   "source": [
    "# Where to go from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab24805",
   "metadata": {},
   "source": [
    "This notebook sets you up with all the functionality you might need to start experimenting with cutting-edge tools.\n",
    "\n",
    "I myself am quite convinced as to [the value of smaller models](https://x.com/radekosmulski/status/1967386084868055175), which has been my motivation for this exploration.\n",
    "\n",
    "I would highly recommend heading over to [the docs for BAML](https://docs.boundaryml.com/guide/introduction/what-is-baml) and checking out how you can modify the functionality I implemented in `baml_src/basic.baml`to better suite your needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
